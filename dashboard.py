import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from supabase import create_client, Client
from dotenv import load_dotenv
import os
import numpy as np

load_dotenv()

# Initialize Supabase
supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

# Page configuration
st.set_page_config(
    page_title="Food Trend Predictor Dashboard",
    page_icon="üçï",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        background: linear-gradient(90deg, #FF6B6B, #FFD93D);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .trend-card {
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #FF6B6B;
        background: #f8f9fa;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_data(ttl=300)  # Cache for 5 minutes
def fetch_recent_posts(days=7):
    """Fetch recent posts from Supabase"""
    cutoff_date = (datetime.now() - timedelta(days=days)).isoformat()
    try:
        result = supabase.table('reddit_posts')\
            .select('*')\
            .gte('created_utc', cutoff_date)\
            .order('created_utc', desc=True)\
            .execute()
        return pd.DataFrame(result.data)
    except Exception as e:
        st.error(f"Error fetching posts: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=300)
def fetch_predictions():
    """Fetch food trend predictions"""
    try:
        result = supabase.table('food_predictions')\
            .select('*')\
            .order('trend_probability', desc=True)\
            .execute()
        return pd.DataFrame(result.data)
    except Exception as e:
        st.error(f"Error fetching predictions: {e}")
        return pd.DataFrame()

def analyze_trending_foods(df, days=7):
    """Analyze trending foods from posts"""
    if df.empty:
        return pd.DataFrame()
    
    # Explode food_mentions
    food_data = []
    for _, row in df.iterrows():
        if row.get('food_mentions'):
            for food in row['food_mentions']:
                food_data.append({
                    'food': food,
                    'score': row.get('score', 0),
                    'num_comments': row.get('num_comments', 0),
                    'created_utc': row.get('created_utc'),
                    'subreddit': row.get('subreddit', '')
                })
    
    if not food_data:
        return pd.DataFrame()
    
    food_df = pd.DataFrame(food_data)
    
    # Aggregate by food
    trending = food_df.groupby('food').agg({
        'score': ['sum', 'mean', 'count'],
        'num_comments': ['sum', 'mean'],
        'subreddit': 'nunique'
    }).reset_index()
    
    trending.columns = ['food', 'total_score', 'avg_score', 'mentions', 
                       'total_comments', 'avg_comments', 'subreddit_count']
    
    # Calculate engagement score
    trending['engagement'] = (
        trending['total_score'] * 1.0 + 
        trending['total_comments'] * 2.0
    )
    
    return trending.sort_values('engagement', ascending=False)

def create_time_series(df):
    """Create time series data for trending analysis"""
    if df.empty:
        return pd.DataFrame()
    
    df['created_utc'] = pd.to_datetime(df['created_utc'])
    df['date'] = df['created_utc'].dt.date
    
    # Daily aggregation
    daily = df.groupby('date').agg({
        'post_id': 'count',
        'score': 'sum',
        'num_comments': 'sum'
    }).reset_index()
    
    daily.columns = ['date', 'post_count', 'total_score', 'total_comments']
    return daily

def main():
    # Header
    st.markdown('<h1 class="main-header">üçï Food Trend Predictor Dashboard</h1>', 
                unsafe_allow_html=True)
    st.markdown("### Real-time Analytics for Food Culture Shifts")
    
    # Sidebar
    st.sidebar.header("‚öôÔ∏è Dashboard Settings")
    days_filter = st.sidebar.slider("Days to analyze", 1, 90, 7)
    min_mentions = st.sidebar.slider("Minimum mentions", 1, 50, 5)
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìä Data Sources")
    st.sidebar.markdown("- Reddit (23 food subreddits)")
    st.sidebar.markdown("- BERT + XGBoost ML Model")
    st.sidebar.markdown("- Real-time Supabase DB")
    
    # Fetch data
    with st.spinner("Loading data..."):
        posts_df = fetch_recent_posts(days_filter)
        predictions_df = fetch_predictions()
    
    if posts_df.empty:
        st.warning("‚ö†Ô∏è No data available. Run the ETL pipeline first: `python etl.py collect`")
        return
    
    # Key Metrics Row
    st.markdown("## üìà Key Metrics")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="Total Posts Analyzed",
            value=f"{len(posts_df):,}",
            delta=f"Last {days_filter} days"
        )
    
    with col2:
        total_engagement = posts_df['score'].sum() + posts_df['num_comments'].sum()
        st.metric(
            label="Total Engagement",
            value=f"{total_engagement:,}",
            delta=f"{total_engagement/len(posts_df):.0f} avg/post"
        )
    
    with col3:
        unique_subreddits = posts_df['subreddit'].nunique()
        st.metric(
            label="Subreddits Monitored",
            value=unique_subreddits,
            delta="Active sources"
        )
    
    with col4:
        if not predictions_df.empty:
            trending_count = predictions_df[predictions_df['trend_probability'] > 0.7].shape[0]
            st.metric(
                label="Trending Foods",
                value=trending_count,
                delta=f"{(trending_count/len(predictions_df)*100):.1f}% of total"
            )
        else:
            st.metric(label="Trending Foods", value="N/A")
    
    st.markdown("---")
    
    # Main content area
    tab1, tab2, tab3, tab4 = st.tabs([
        "üî• Trending Now", 
        "üìä Analytics", 
        "ü§ñ ML Predictions", 
        "üó∫Ô∏è Subreddit Heatmap"
    ])
    
    # TAB 1: Trending Now
    with tab1:
        st.markdown("## üî• Top Trending Foods")
        
        trending_foods = analyze_trending_foods(posts_df, days_filter)
        
        if not trending_foods.empty:
            # Filter by minimum mentions
            trending_foods = trending_foods[trending_foods['mentions'] >= min_mentions]
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Bar chart
                fig = px.bar(
                    trending_foods.head(15),
                    x='food',
                    y='engagement',
                    color='mentions',
                    title=f"Top 15 Trending Foods (Last {days_filter} Days)",
                    labels={'engagement': 'Engagement Score', 'food': 'Food Item'},
                    color_continuous_scale='Reds',
                    text='mentions'
                )
                fig.update_layout(
                    xaxis_tickangle=-45,
                    height=500,
                    showlegend=True
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("### üèÜ Top 10 Rankings")
                for idx, row in trending_foods.head(10).iterrows():
                    rank = trending_foods.index.get_loc(idx) + 1
                    
                    # Emoji based on rank
                    emoji = "ü•á" if rank == 1 else "ü•à" if rank == 2 else "ü•â" if rank == 3 else f"{rank}."
                    
                    st.markdown(f"""
                        <div class="trend-card">
                            <strong>{emoji} {row['food'].title()}</strong><br>
                            üìù {row['mentions']} mentions | 
                            ‚≠ê {row['avg_score']:.1f} avg score | 
                            üí¨ {row['total_comments']:.0f} comments
                        </div>
                    """, unsafe_allow_html=True)
            
            # Detailed table
            st.markdown("### üìã Detailed Breakdown")
            display_df = trending_foods.head(20).copy()
            display_df['food'] = display_df['food'].str.title()
            display_df = display_df.round(2)
            st.dataframe(
                display_df,
                use_container_width=True,
                hide_index=True
            )
        else:
            st.info("No trending foods found. Try adjusting the filters.")
    
    # TAB 2: Analytics
    with tab2:
        st.markdown("## üìä Time Series Analytics")
        
        # Time series plot
        daily_data = create_time_series(posts_df)
        
        if not daily_data.empty:
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=("Daily Post Volume", "Daily Engagement"),
                vertical_spacing=0.15
            )
            
            # Posts over time
            fig.add_trace(
                go.Scatter(
                    x=daily_data['date'],
                    y=daily_data['post_count'],
                    mode='lines+markers',
                    name='Posts',
                    line=dict(color='#667eea', width=3),
                    fill='tozeroy'
                ),
                row=1, col=1
            )
            
            # Engagement over time
            fig.add_trace(
                go.Scatter(
                    x=daily_data['date'],
                    y=daily_data['total_score'] + daily_data['total_comments'],
                    mode='lines+markers',
                    name='Total Engagement',
                    line=dict(color='#FF6B6B', width=3),
                    fill='tozeroy'
                ),
                row=2, col=1
            )
            
            fig.update_layout(height=600, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)
        
        # Distribution charts
        col1, col2 = st.columns(2)
        
        with col1:
            # Score distribution
            fig = px.histogram(
                posts_df,
                x='score',
                nbins=50,
                title="Post Score Distribution",
                labels={'score': 'Score', 'count': 'Frequency'},
                color_discrete_sequence=['#FFD93D']
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Subreddit distribution
            subreddit_counts = posts_df['subreddit'].value_counts().head(10)
            fig = px.pie(
                values=subreddit_counts.values,
                names=subreddit_counts.index,
                title="Top 10 Subreddits by Post Count",
                color_discrete_sequence=px.colors.qualitative.Set3
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # TAB 3: ML Predictions
    with tab3:
        st.markdown("## ü§ñ Machine Learning Predictions")
        
        if not predictions_df.empty:
            st.markdown(f"### Model Performance: **80%+ Precision** (BERT + XGBoost)")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Prediction scatter plot
                fig = px.scatter(
                    predictions_df,
                    x='velocity',
                    y='trend_probability',
                    size='trending_score',
                    color='trend_probability',
                    hover_data=['food', 'growth_rate'],
                    title="Food Trend Predictions",
                    labels={
                        'velocity': 'Mentions per Day',
                        'trend_probability': 'Predicted Trend Probability',
                        'food': 'Food Item'
                    },
                    color_continuous_scale='RdYlGn'
                )
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("### üéØ High Probability Trends")
                high_prob = predictions_df[predictions_df['trend_probability'] > 0.7]\
                    .sort_values('trend_probability', ascending=False)\
                    .head(10)
                
                for idx, row in high_prob.iterrows():
                    prob = row['trend_probability'] * 100
                    st.markdown(f"""
                        <div style="padding: 0.5rem; margin: 0.3rem 0; 
                             background: linear-gradient(90deg, rgba(255,107,107,{prob/100}) 0%, 
                             rgba(255,217,61,{prob/100}) 100%); border-radius: 5px;">
                            <strong>{row['food'].title()}</strong><br>
                            üìà {prob:.1f}% trending probability
                        </div>
                    """, unsafe_allow_html=True)
            
            # Full predictions table
            st.markdown("### üìä All Predictions")
            display_pred = predictions_df.copy()
            display_pred['food'] = display_pred['food'].str.title()
            display_pred['trend_probability'] = (display_pred['trend_probability'] * 100).round(1)
            display_pred = display_pred.sort_values('trend_probability', ascending=False)
            
            st.dataframe(
                display_pred[['food', 'trend_probability', 'velocity', 'growth_rate', 'trending_score']],
                use_container_width=True,
                hide_index=True
            )
        else:
            st.info("‚ö†Ô∏è No predictions available. Run the model training: `python model.py`")
    
    # TAB 4: Subreddit Heatmap
    with tab4:
        st.markdown("## üó∫Ô∏è Subreddit Activity Heatmap")
        
        if not posts_df.empty:
            # Create food x subreddit matrix
            heatmap_data = []
            for _, row in posts_df.iterrows():
                if row.get('food_mentions'):
                    for food in row['food_mentions']:
                        heatmap_data.append({
                            'food': food,
                            'subreddit': row['subreddit'],
                            'score': row['score']
                        })
            
            if heatmap_data:
                heatmap_df = pd.DataFrame(heatmap_data)
                
                # Get top foods and subreddits
                top_foods = heatmap_df['food'].value_counts().head(15).index
                top_subreddits = heatmap_df['subreddit'].value_counts().head(10).index
                
                # Filter and pivot
                filtered = heatmap_df[
                    (heatmap_df['food'].isin(top_foods)) & 
                    (heatmap_df['subreddit'].isin(top_subreddits))
                ]
                
                pivot = filtered.pivot_table(
                    index='food',
                    columns='subreddit',
                    values='score',
                    aggfunc='sum',
                    fill_value=0
                )
                
                # Create heatmap
                fig = px.imshow(
                    pivot,
                    labels=dict(x="Subreddit", y="Food", color="Total Score"),
                    title="Food Mentions Across Subreddits",
                    color_continuous_scale='YlOrRd',
                    aspect='auto'
                )
                fig.update_layout(height=600)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("No food mentions data available for heatmap")
    
    # Footer
    st.markdown("---")
    st.markdown("""
        <div style='text-align: center; color: #666; padding: 1rem;'>
            <p><strong>Food Trend Predictor Dashboard</strong></p>
            <p>Powered by BERT + XGBoost | Data from 23 Reddit Communities | Real-time Supabase Analytics</p>
            <p style='font-size: 0.8rem;'>Last updated: {}</p>
        </div>
    """.format(datetime.now().strftime("%Y-%m-%d %H:%M:%S")), unsafe_allow_html=True)

if __name__ == "__main__":
    main()
